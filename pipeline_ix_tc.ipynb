{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c017181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "HYPERPARAMETER OPTIMIZATION COMPARISON STUDY\n",
      "Comparing Grid Search, Random Search, Bayesian Optimization, and Genetic Algorithms\n",
      "====================================================================================================\n",
      "ðŸ“¥ Downloading dataset from Kaggle...\n",
      "âœ“ Dataset loaded: 768 samples, 9 features\n",
      "\n",
      "ðŸ“Š Data split:\n",
      "   Training set: 537 samples\n",
      "   Test set: 231 samples\n",
      "   Class distribution (train): {np.int64(0): np.int64(350), np.int64(1): np.int64(187)}\n",
      "\n",
      "ðŸ”„ Cross-validation: 5-fold stratified\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# PART 1: SUPPORT VECTOR MACHINE (SVM) OPTIMIZATION\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "HYPERPARAMETER OPTIMIZATION: SVM\n",
      "================================================================================\n",
      "\n",
      "[1/4] Running Grid Search...\n",
      "   âœ“ Completed in 19.69s | Best CV F1: 0.6621\n",
      "\n",
      "[2/4] Running Random Search...\n",
      "   âœ“ Completed in 0.99s | Best CV F1: 0.6567\n",
      "\n",
      "[3/4] Running Bayesian Optimization...\n",
      "   âœ“ Completed in 88.85s | Best CV F1: 0.6631\n",
      "\n",
      "[4/4] Running Genetic Algorithm...\n",
      "   âœ“ Completed in 163.39s | Best CV F1: 0.6599\n",
      "\n",
      "################################################################################\n",
      "# PART 2: MULTI-LAYER PERCEPTRON (MLP) OPTIMIZATION\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "HYPERPARAMETER OPTIMIZATION: MLP\n",
      "================================================================================\n",
      "\n",
      "[1/4] Running Grid Search...\n",
      "   âœ“ Completed in 197.43s | Best CV F1: 0.6503\n",
      "\n",
      "[2/4] Running Random Search...\n",
      "   âœ“ Completed in 7.31s | Best CV F1: 0.6340\n",
      "\n",
      "[3/4] Running Bayesian Optimization...\n",
      "   âœ— Failed: Not all points are within the bounds of the space.\n",
      "\n",
      "[4/4] Running Genetic Algorithm...\n",
      "   âœ“ Completed in 36.47s | Best CV F1: 0.6516\n",
      "\n",
      "################################################################################\n",
      "# RESULTS ANALYSIS\n",
      "################################################################################\n",
      "\n",
      "====================================================================================================\n",
      "HYPERPARAMETER OPTIMIZATION RESULTS SUMMARY\n",
      "====================================================================================================\n",
      "\n",
      "ðŸ† BEST OVERALL CONFIGURATION:\n",
      "   Model: SVM\n",
      "   Strategy: Random Search\n",
      "   Test F1 Score: 0.6707\n",
      "   Test Accuracy: 0.7662\n",
      "   Test ROC-AUC: 0.8401\n",
      "   Optimization Time: 0.99s\n",
      "   Best Parameters: {'clf__C': np.float64(1.2173252504194043), 'clf__class_weight': 'balanced', 'clf__gamma': np.float64(0.007362945281639215), 'clf__kernel': 'linear'}\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "RESULTS BY MODEL:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "SVM:\n",
      "  â€¢ Grid Search               | F1: 0.6145 | Accuracy: 0.7229 | ROC-AUC: 0.7993 | Time:   19.69s\n",
      "  â€¢ Random Search             | F1: 0.6707 | Accuracy: 0.7662 | ROC-AUC: 0.8401 | Time:    0.99s\n",
      "  â€¢ Bayesian Optimization     | F1: 0.6364 | Accuracy: 0.7229 | ROC-AUC: 0.8128 | Time:   88.85s\n",
      "  â€¢ Genetic Algorithm         | F1: 0.6707 | Accuracy: 0.7662 | ROC-AUC: 0.8400 | Time:  163.39s\n",
      "\n",
      "MLP:\n",
      "  â€¢ Grid Search               | F1: 0.5789 | Accuracy: 0.7229 | ROC-AUC: 0.8214 | Time:  197.43s\n",
      "  â€¢ Random Search             | F1: 0.5811 | Accuracy: 0.7316 | ROC-AUC: 0.8370 | Time:    7.31s\n",
      "  â€¢ Genetic Algorithm         | F1: 0.5793 | Accuracy: 0.7359 | ROC-AUC: 0.8333 | Time:   36.47s\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "STRATEGY PERFORMANCE COMPARISON (Average across models):\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Bayesian Optimization     | F1: 0.6364 (Â±nan) | Acc: 0.7229 | Avg Time:   88.85s\n",
      "  Genetic Algorithm         | F1: 0.6250 (Â±0.0646) | Acc: 0.7511 | Avg Time:   99.93s\n",
      "  Grid Search               | F1: 0.5967 (Â±0.0251) | Acc: 0.7229 | Avg Time:  108.56s\n",
      "  Random Search             | F1: 0.6259 (Â±0.0634) | Acc: 0.7489 | Avg Time:    4.15s\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "DETAILED RESULTS TABLE:\n",
      "====================================================================================================\n",
      "model              strategy   time_s  cv_f1_mean  cv_f1_std  test_f1  test_accuracy  test_precision  test_recall  test_roc_auc  test_kappa\n",
      "  SVM           Grid Search  19.6930      0.6621     0.0712   0.6145         0.7229          0.6000       0.6296        0.7993      0.3984\n",
      "  SVM         Random Search   0.9865      0.6567     0.0970   0.6707         0.7662          0.6627       0.6790        0.8401      0.4896\n",
      "  SVM Bayesian Optimization  88.8459      0.6631     0.0999   0.6364         0.7229          0.5895       0.6914        0.8128      0.4149\n",
      "  SVM     Genetic Algorithm 163.3905      0.6599     0.0938   0.6707         0.7662          0.6627       0.6790        0.8400      0.4896\n",
      "  MLP           Grid Search 197.4293      0.6503     0.1243   0.5789         0.7229          0.6197       0.5432        0.8214      0.3738\n",
      "  MLP         Random Search   7.3141      0.6340     0.0826   0.5811         0.7316          0.6418       0.5309        0.8370      0.3862\n",
      "  MLP     Genetic Algorithm  36.4667      0.6516     0.0822   0.5793         0.7359          0.6562       0.5185        0.8333      0.3907\n",
      "====================================================================================================\n",
      "ðŸ“Š Detailed results saved to: optimization_results.csv\n",
      "\n",
      "âœ… Hyperparameter optimization study completed successfully!\n",
      "   Total optimization time: 514.13s\n",
      "   Number of configurations tested: 7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hyperparameter Optimization Comparison Study\n",
    "=============================================\n",
    "Compares different hyperparameter optimization strategies (Grid Search, Random Search, \n",
    "Bayesian Optimization, and Genetic Algorithm) on SVM and MLP classifiers using the \n",
    "Pima Indians Diabetes dataset.\n",
    "\n",
    "Author: Data Science Team\n",
    "Date: 2024\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "from time import perf_counter\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import loguniform\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    cohen_kappa_score,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn_genetic import GASearchCV\n",
    "from sklearn_genetic.space import Categorical as GCategorical\n",
    "from sklearn_genetic.space import Continuous, Integer as GInteger\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Categorical, Integer, Real\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# ================================================================================\n",
    "# CONFIGURATION\n",
    "# ================================================================================\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.3\n",
    "CV_SPLITS = 5\n",
    "PRIMARY_METRIC = \"f1\"\n",
    "\n",
    "SCORING_METRICS = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"precision\": make_scorer(precision_score, zero_division=0),\n",
    "    \"recall\": make_scorer(recall_score, zero_division=0),\n",
    "    \"f1\": \"f1\",\n",
    "    \"roc_auc\": \"roc_auc\",\n",
    "    \"kappa\": make_scorer(cohen_kappa_score),\n",
    "}\n",
    "\n",
    "# Hyperparameter search configuration\n",
    "RANDOM_SEARCH_ITERATIONS = 20\n",
    "BAYESIAN_SEARCH_ITERATIONS = 30\n",
    "GENETIC_GENERATIONS = 20\n",
    "GENETIC_POPULATION_SIZE = 30\n",
    "\n",
    "\n",
    "# ================================================================================\n",
    "# DATA LOADING AND PREPROCESSING\n",
    "# ================================================================================\n",
    "\n",
    "def load_diabetes_dataset() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Download and load the Pima Indians Diabetes dataset from Kaggle.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Loaded dataset with all features and target variable.\n",
    "    \"\"\"\n",
    "    print(\"ðŸ“¥ Downloading dataset from Kaggle...\")\n",
    "    dataset_path = kagglehub.dataset_download(\"uciml/pima-indians-diabetes-database\")\n",
    "    csv_path = os.path.join(dataset_path, \"diabetes.csv\")\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"âœ“ Dataset loaded: {df.shape[0]} samples, {df.shape[1]} features\\n\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_data(df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Split and scale the dataset for training and testing.\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame containing features and target.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (X_train, X_test, y_train, y_test) as scaled numpy arrays.\n",
    "    \"\"\"\n",
    "    X = df.drop(\"Outcome\", axis=1)\n",
    "    y = df[\"Outcome\"]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    print(f\"ðŸ“Š Data split:\")\n",
    "    print(f\"   Training set: {X_train_scaled.shape[0]} samples\")\n",
    "    print(f\"   Test set: {X_test_scaled.shape[0]} samples\")\n",
    "    print(f\"   Class distribution (train): {dict(zip(*np.unique(y_train, return_counts=True)))}\\n\")\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "\n",
    "\n",
    "# ================================================================================\n",
    "# EVALUATION UTILITIES\n",
    "# ================================================================================\n",
    "\n",
    "def evaluate_model_on_test_set(estimator, X_test: np.ndarray, y_test: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluate a trained model on the test set with multiple metrics.\n",
    "    \n",
    "    Args:\n",
    "        estimator: Trained model estimator.\n",
    "        X_test: Test features.\n",
    "        y_test: Test labels.\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing all evaluation metrics.\n",
    "    \"\"\"\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    \n",
    "    # Get probability estimates for ROC AUC\n",
    "    if hasattr(estimator, \"predict_proba\"):\n",
    "        y_proba = estimator.predict_proba(X_test)[:, 1]\n",
    "    elif hasattr(estimator, \"decision_function\"):\n",
    "        y_proba = estimator.decision_function(X_test)\n",
    "    else:\n",
    "        y_proba = None\n",
    "    \n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred, zero_division=0),\n",
    "        \"recall\": recall_score(y_test, y_pred, zero_division=0),\n",
    "        \"f1\": f1_score(y_test, y_pred),\n",
    "        \"kappa\": cohen_kappa_score(y_test, y_pred),\n",
    "    }\n",
    "    \n",
    "    if y_proba is not None:\n",
    "        metrics[\"roc_auc\"] = roc_auc_score(y_test, y_proba)\n",
    "    else:\n",
    "        metrics[\"roc_auc\"] = np.nan\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def extract_cv_results(search_object) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Extract cross-validation results from a search object.\n",
    "    \n",
    "    Args:\n",
    "        search_object: Fitted hyperparameter search object.\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing CV metrics (mean and std).\n",
    "    \"\"\"\n",
    "    best_idx = getattr(search_object, \"best_index_\", None)\n",
    "    cv_results = {}\n",
    "    \n",
    "    # GASearchCV and BayesSearchCV only have mean_test_score and std_test_score\n",
    "    if hasattr(search_object, \"cv_results_\") and \"mean_test_score\" in search_object.cv_results_:\n",
    "        if best_idx is None:\n",
    "            best_idx = 0\n",
    "        cv_results[\"cv_f1_mean\"] = search_object.cv_results_[\"mean_test_score\"][best_idx]\n",
    "        cv_results[\"cv_f1_std\"] = search_object.cv_results_[\"std_test_score\"][best_idx]\n",
    "        return cv_results\n",
    "    \n",
    "    # For GridSearchCV and RandomizedSearchCV, extract all metrics\n",
    "    for metric_name in SCORING_METRICS.keys():\n",
    "        try:\n",
    "            cv_results[f\"cv_{metric_name}_mean\"] = search_object.cv_results_[f\"mean_test_{metric_name}\"][best_idx]\n",
    "            cv_results[f\"cv_{metric_name}_std\"] = search_object.cv_results_[f\"std_test_{metric_name}\"][best_idx]\n",
    "        except (KeyError, TypeError):\n",
    "            pass\n",
    "    \n",
    "    return cv_results\n",
    "\n",
    "\n",
    "# ================================================================================\n",
    "# HYPERPARAMETER SEARCH SPACES\n",
    "# ================================================================================\n",
    "\n",
    "def get_svm_search_spaces() -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Define hyperparameter search spaces for SVM classifier.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing search spaces for each optimization strategy.\n",
    "    \"\"\"\n",
    "    grid_space = [\n",
    "        {\n",
    "            \"clf__kernel\": [\"linear\"],\n",
    "            \"clf__C\": [1e-3, 1e-2, 1e-1, 1, 10, 1e2, 1e3],\n",
    "            \"clf__class_weight\": [None, \"balanced\"],\n",
    "        },\n",
    "        {\n",
    "            \"clf__kernel\": [\"rbf\"],\n",
    "            \"clf__C\": [1e-3, 1e-2, 1e-1, 1, 10, 1e2, 1e3],\n",
    "            \"clf__gamma\": [1e-4, 1e-3, 1e-2, 1e-1, 1.0],\n",
    "            \"clf__class_weight\": [None, \"balanced\"],\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    random_space = {\n",
    "        \"clf__kernel\": [\"linear\", \"rbf\"],\n",
    "        \"clf__C\": loguniform(1e-3, 1e3),\n",
    "        \"clf__gamma\": loguniform(1e-4, 1.0),\n",
    "        \"clf__class_weight\": [None, \"balanced\"],\n",
    "    }\n",
    "    \n",
    "    # Bayesian optimization: single dict (gamma ignored when kernel='linear')\n",
    "    bayesian_space = {\n",
    "        \"clf__kernel\": Categorical([\"linear\", \"rbf\"]),\n",
    "        \"clf__C\": Real(1e-3, 1e3, prior=\"log-uniform\"),\n",
    "        \"clf__gamma\": Real(1e-4, 1.0, prior=\"log-uniform\"),\n",
    "        \"clf__class_weight\": Categorical([None, \"balanced\"]),\n",
    "    }\n",
    "    \n",
    "    genetic_space = {\n",
    "        \"clf__kernel\": GCategorical([\"linear\", \"rbf\"]),\n",
    "        \"clf__C\": Continuous(1e-3, 1e3, distribution=\"log-uniform\"),\n",
    "        \"clf__gamma\": Continuous(1e-4, 1.0, distribution=\"log-uniform\"),\n",
    "        \"clf__class_weight\": GCategorical([None, \"balanced\"]),\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        \"grid\": grid_space,\n",
    "        \"random\": random_space,\n",
    "        \"bayesian\": bayesian_space,\n",
    "        \"genetic\": genetic_space,\n",
    "    }\n",
    "\n",
    "\n",
    "def get_mlp_search_spaces() -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Define hyperparameter search spaces for MLP classifier.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing search spaces for each optimization strategy.\n",
    "    \"\"\"\n",
    "    hidden_layer_options = [(64,), (128,), (64, 32), (128, 64), (256, 128)]\n",
    "    \n",
    "    grid_space = {\n",
    "        \"clf__hidden_layer_sizes\": hidden_layer_options,\n",
    "        \"clf__activation\": [\"relu\", \"tanh\"],\n",
    "        \"clf__solver\": [\"adam\", \"lbfgs\"],\n",
    "        \"clf__alpha\": [1e-6, 1e-5, 1e-4, 1e-3, 1e-2],\n",
    "        \"clf__learning_rate_init\": [1e-4, 1e-3, 1e-2],\n",
    "        \"clf__max_iter\": [300, 600],\n",
    "        \"clf__early_stopping\": [True],\n",
    "    }\n",
    "    \n",
    "    random_space = {\n",
    "        \"clf__hidden_layer_sizes\": hidden_layer_options,\n",
    "        \"clf__activation\": [\"relu\", \"tanh\"],\n",
    "        \"clf__solver\": [\"adam\", \"lbfgs\"],\n",
    "        \"clf__alpha\": loguniform(1e-6, 1e-2),\n",
    "        \"clf__learning_rate_init\": loguniform(1e-4, 1e-2),\n",
    "        \"clf__max_iter\": [300, 600],\n",
    "        \"clf__early_stopping\": [True],\n",
    "    }\n",
    "    \n",
    "    bayesian_space = {\n",
    "        \"clf__hidden_layer_sizes\": Categorical(hidden_layer_options),\n",
    "        \"clf__activation\": Categorical([\"relu\", \"tanh\"]),\n",
    "        \"clf__solver\": Categorical([\"adam\", \"lbfgs\"]),\n",
    "        \"clf__alpha\": Real(1e-6, 1e-2, prior=\"log-uniform\"),\n",
    "        \"clf__learning_rate_init\": Real(1e-4, 1e-2, prior=\"log-uniform\"),\n",
    "        \"clf__max_iter\": Integer(300, 600),\n",
    "        \"clf__early_stopping\": Categorical([True]),\n",
    "    }\n",
    "    \n",
    "    genetic_space = {\n",
    "        \"clf__hidden_layer_sizes\": GCategorical(hidden_layer_options),\n",
    "        \"clf__activation\": GCategorical([\"relu\", \"tanh\"]),\n",
    "        \"clf__solver\": GCategorical([\"adam\", \"lbfgs\"]),\n",
    "        \"clf__alpha\": Continuous(1e-6, 1e-2, distribution=\"log-uniform\"),\n",
    "        \"clf__learning_rate_init\": Continuous(1e-4, 1e-2, distribution=\"log-uniform\"),\n",
    "        \"clf__max_iter\": GInteger(300, 600),\n",
    "        \"clf__early_stopping\": GCategorical([True]),\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        \"grid\": grid_space,\n",
    "        \"random\": random_space,\n",
    "        \"bayesian\": bayesian_space,\n",
    "        \"genetic\": genetic_space,\n",
    "    }\n",
    "\n",
    "\n",
    "# ================================================================================\n",
    "# HYPERPARAMETER OPTIMIZATION\n",
    "# ================================================================================\n",
    "\n",
    "def run_hyperparameter_search(\n",
    "    model_name: str,\n",
    "    pipeline: Pipeline,\n",
    "    search_spaces: Dict[str, Any],\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    cv: KFold,\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Run all hyperparameter optimization strategies for a given model.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the model being optimized.\n",
    "        pipeline: sklearn Pipeline with preprocessing and classifier.\n",
    "        search_spaces: Dictionary of search spaces for each strategy.\n",
    "        X_train: Training features.\n",
    "        y_train: Training labels.\n",
    "        X_test: Test features.\n",
    "        y_test: Test labels.\n",
    "        cv: Cross-validation splitter.\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries containing results for each optimization strategy.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"HYPERPARAMETER OPTIMIZATION: {model_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # ============================================================================\n",
    "    # 1. GRID SEARCH\n",
    "    # ============================================================================\n",
    "    print(f\"\\n[1/4] Running Grid Search...\")\n",
    "    start_time = perf_counter()\n",
    "    \n",
    "    try:\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=pipeline,\n",
    "            param_grid=search_spaces[\"grid\"],\n",
    "            cv=cv,\n",
    "            scoring=SCORING_METRICS,\n",
    "            refit=PRIMARY_METRIC,\n",
    "            n_jobs=-1,\n",
    "            verbose=0,\n",
    "        )\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        elapsed_time = perf_counter() - start_time\n",
    "        \n",
    "        result = {\n",
    "            \"model\": model_name,\n",
    "            \"strategy\": \"Grid Search\",\n",
    "            \"time_s\": elapsed_time,\n",
    "            \"best_params\": grid_search.best_params_,\n",
    "        }\n",
    "        result.update(extract_cv_results(grid_search))\n",
    "        result.update({f\"test_{k}\": v for k, v in evaluate_model_on_test_set(grid_search.best_estimator_, X_test, y_test).items()})\n",
    "        results.append(result)\n",
    "        print(f\"   âœ“ Completed in {elapsed_time:.2f}s | Best CV F1: {result.get('cv_f1_mean', 0):.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âœ— Failed: {str(e)}\")\n",
    "    \n",
    "    # ============================================================================\n",
    "    # 2. RANDOM SEARCH\n",
    "    # ============================================================================\n",
    "    print(f\"\\n[2/4] Running Random Search...\")\n",
    "    start_time = perf_counter()\n",
    "    \n",
    "    try:\n",
    "        random_search = RandomizedSearchCV(\n",
    "            estimator=pipeline,\n",
    "            param_distributions=search_spaces[\"random\"],\n",
    "            n_iter=RANDOM_SEARCH_ITERATIONS,\n",
    "            cv=cv,\n",
    "            scoring=SCORING_METRICS,\n",
    "            refit=PRIMARY_METRIC,\n",
    "            n_jobs=-1,\n",
    "            random_state=RANDOM_STATE,\n",
    "            verbose=0,\n",
    "        )\n",
    "        random_search.fit(X_train, y_train)\n",
    "        elapsed_time = perf_counter() - start_time\n",
    "        \n",
    "        result = {\n",
    "            \"model\": model_name,\n",
    "            \"strategy\": \"Random Search\",\n",
    "            \"time_s\": elapsed_time,\n",
    "            \"best_params\": random_search.best_params_,\n",
    "        }\n",
    "        result.update(extract_cv_results(random_search))\n",
    "        result.update({f\"test_{k}\": v for k, v in evaluate_model_on_test_set(random_search.best_estimator_, X_test, y_test).items()})\n",
    "        results.append(result)\n",
    "        print(f\"   âœ“ Completed in {elapsed_time:.2f}s | Best CV F1: {result.get('cv_f1_mean', 0):.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âœ— Failed: {str(e)}\")\n",
    "    \n",
    "    # ============================================================================\n",
    "    # 3. BAYESIAN OPTIMIZATION\n",
    "    # ============================================================================\n",
    "    print(f\"\\n[3/4] Running Bayesian Optimization...\")\n",
    "    start_time = perf_counter()\n",
    "    \n",
    "    try:\n",
    "        bayesian_search = BayesSearchCV(\n",
    "            estimator=pipeline,\n",
    "            search_spaces=search_spaces[\"bayesian\"],\n",
    "            n_iter=BAYESIAN_SEARCH_ITERATIONS,\n",
    "            cv=cv,\n",
    "            scoring=make_scorer(f1_score),  # Single metric for BayesSearchCV\n",
    "            n_jobs=-1,\n",
    "            random_state=RANDOM_STATE,\n",
    "            verbose=0,\n",
    "        )\n",
    "        bayesian_search.fit(X_train, y_train)\n",
    "        elapsed_time = perf_counter() - start_time\n",
    "        \n",
    "        result = {\n",
    "            \"model\": model_name,\n",
    "            \"strategy\": \"Bayesian Optimization\",\n",
    "            \"time_s\": elapsed_time,\n",
    "            \"best_params\": bayesian_search.best_params_,\n",
    "        }\n",
    "        result.update(extract_cv_results(bayesian_search))\n",
    "        result.update({f\"test_{k}\": v for k, v in evaluate_model_on_test_set(bayesian_search.best_estimator_, X_test, y_test).items()})\n",
    "        results.append(result)\n",
    "        print(f\"   âœ“ Completed in {elapsed_time:.2f}s | Best CV F1: {result.get('cv_f1_mean', 0):.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âœ— Failed: {str(e)}\")\n",
    "    \n",
    "    # ============================================================================\n",
    "    # 4. GENETIC ALGORITHM\n",
    "    # ============================================================================\n",
    "    print(f\"\\n[4/4] Running Genetic Algorithm...\")\n",
    "    start_time = perf_counter()\n",
    "    \n",
    "    try:\n",
    "        genetic_search = GASearchCV(\n",
    "            estimator=pipeline,\n",
    "            cv=cv,\n",
    "            scoring=make_scorer(f1_score),\n",
    "            n_jobs=-1,\n",
    "            param_grid=search_spaces[\"genetic\"],\n",
    "            generations=GENETIC_GENERATIONS,\n",
    "            population_size=GENETIC_POPULATION_SIZE,\n",
    "            tournament_size=3,\n",
    "            elitism=True,\n",
    "            mutation_probability=0.1,\n",
    "            crossover_probability=0.8,\n",
    "            verbose=False,\n",
    "        )\n",
    "        genetic_search.fit(X_train, y_train)\n",
    "        elapsed_time = perf_counter() - start_time\n",
    "        \n",
    "        result = {\n",
    "            \"model\": model_name,\n",
    "            \"strategy\": \"Genetic Algorithm\",\n",
    "            \"time_s\": elapsed_time,\n",
    "            \"best_params\": genetic_search.best_params_,\n",
    "        }\n",
    "        result.update(extract_cv_results(genetic_search))\n",
    "        result.update({f\"test_{k}\": v for k, v in evaluate_model_on_test_set(genetic_search.best_estimator_, X_test, y_test).items()})\n",
    "        results.append(result)\n",
    "        print(f\"   âœ“ Completed in {elapsed_time:.2f}s | Best CV F1: {result.get('cv_f1_mean', 0):.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âœ— Failed: {str(e)}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# ================================================================================\n",
    "# RESULTS PRESENTATION\n",
    "# ================================================================================\n",
    "\n",
    "def display_results_summary(results_df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Display a comprehensive summary of optimization results.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame containing all optimization results.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"HYPERPARAMETER OPTIMIZATION RESULTS SUMMARY\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    # Overall best model\n",
    "    best_idx = results_df[\"test_f1\"].idxmax()\n",
    "    best_result = results_df.loc[best_idx]\n",
    "    \n",
    "    print(f\"\\nðŸ† BEST OVERALL CONFIGURATION:\")\n",
    "    print(f\"   Model: {best_result['model']}\")\n",
    "    print(f\"   Strategy: {best_result['strategy']}\")\n",
    "    print(f\"   Test F1 Score: {best_result['test_f1']:.4f}\")\n",
    "    print(f\"   Test Accuracy: {best_result['test_accuracy']:.4f}\")\n",
    "    print(f\"   Test ROC-AUC: {best_result['test_roc_auc']:.4f}\")\n",
    "    print(f\"   Optimization Time: {best_result['time_s']:.2f}s\")\n",
    "    print(f\"   Best Parameters: {best_result['best_params']}\")\n",
    "    \n",
    "    # Summary by model\n",
    "    print(f\"\\n{'â”€'*100}\")\n",
    "    print(\"RESULTS BY MODEL:\")\n",
    "    print(f\"{'â”€'*100}\")\n",
    "    \n",
    "    for model_name in results_df[\"model\"].unique():\n",
    "        model_results = results_df[results_df[\"model\"] == model_name]\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        \n",
    "        for _, row in model_results.iterrows():\n",
    "            print(f\"  â€¢ {row['strategy']:25s} | F1: {row['test_f1']:.4f} | \"\n",
    "                  f\"Accuracy: {row['test_accuracy']:.4f} | \"\n",
    "                  f\"ROC-AUC: {row['test_roc_auc']:.4f} | \"\n",
    "                  f\"Time: {row['time_s']:7.2f}s\")\n",
    "    \n",
    "    # Performance comparison\n",
    "    print(f\"\\n{'â”€'*100}\")\n",
    "    print(\"STRATEGY PERFORMANCE COMPARISON (Average across models):\")\n",
    "    print(f\"{'â”€'*100}\")\n",
    "    \n",
    "    strategy_summary = results_df.groupby(\"strategy\").agg({\n",
    "        \"test_f1\": [\"mean\", \"std\"],\n",
    "        \"test_accuracy\": [\"mean\", \"std\"],\n",
    "        \"time_s\": [\"mean\", \"std\"]\n",
    "    }).round(4)\n",
    "    \n",
    "    for strategy in strategy_summary.index:\n",
    "        f1_mean = strategy_summary.loc[strategy, (\"test_f1\", \"mean\")]\n",
    "        f1_std = strategy_summary.loc[strategy, (\"test_f1\", \"std\")]\n",
    "        acc_mean = strategy_summary.loc[strategy, (\"test_accuracy\", \"mean\")]\n",
    "        time_mean = strategy_summary.loc[strategy, (\"time_s\", \"mean\")]\n",
    "        \n",
    "        print(f\"  {strategy:25s} | F1: {f1_mean:.4f} (Â±{f1_std:.4f}) | \"\n",
    "              f\"Acc: {acc_mean:.4f} | Avg Time: {time_mean:7.2f}s\")\n",
    "    \n",
    "    print(f\"\\n{'='*100}\\n\")\n",
    "\n",
    "\n",
    "def save_detailed_results(results_df: pd.DataFrame, output_path: str = \"optimization_results.csv\") -> None:\n",
    "    \"\"\"\n",
    "    Save detailed results to a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame containing all results.\n",
    "        output_path: Path where to save the CSV file.\n",
    "    \"\"\"\n",
    "    results_df.to_csv(output_path, index=False)\n",
    "    print(f\"ðŸ“Š Detailed results saved to: {output_path}\")\n",
    "\n",
    "\n",
    "def display_detailed_table(results_df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Display detailed results table with formatting.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame containing all results.\n",
    "    \"\"\"\n",
    "    print(\"\\nDETAILED RESULTS TABLE:\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    # Configure pandas display options\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.precision', 4)\n",
    "    \n",
    "    # Select and order columns for display\n",
    "    display_cols = [\n",
    "        \"model\", \"strategy\", \"time_s\",\n",
    "        \"cv_f1_mean\", \"cv_f1_std\",\n",
    "        \"test_f1\", \"test_accuracy\", \"test_precision\", \"test_recall\",\n",
    "        \"test_roc_auc\", \"test_kappa\"\n",
    "    ]\n",
    "    display_cols = [col for col in display_cols if col in results_df.columns]\n",
    "    \n",
    "    print(results_df[display_cols].to_string(index=False))\n",
    "    print(\"=\"*100)\n",
    "\n",
    "\n",
    "# ================================================================================\n",
    "# MAIN EXECUTION\n",
    "# ================================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function for the hyperparameter optimization study.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"HYPERPARAMETER OPTIMIZATION COMPARISON STUDY\")\n",
    "    print(\"Comparing Grid Search, Random Search, Bayesian Optimization, and Genetic Algorithms\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    # Load and prepare data\n",
    "    df = load_diabetes_dataset()\n",
    "    X_train, X_test, y_train, y_test = prepare_data(df)\n",
    "    \n",
    "    # Setup cross-validation\n",
    "    cv = KFold(n_splits=CV_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    print(f\"ðŸ”„ Cross-validation: {CV_SPLITS}-fold stratified\\n\")\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    # ============================================================================\n",
    "    # SVM OPTIMIZATION\n",
    "    # ============================================================================\n",
    "    print(f\"\\n{'#'*80}\")\n",
    "    print(\"# PART 1: SUPPORT VECTOR MACHINE (SVM) OPTIMIZATION\")\n",
    "    print(f\"{'#'*80}\")\n",
    "    \n",
    "    svm_pipeline = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", SVC(probability=True, random_state=RANDOM_STATE))\n",
    "    ])\n",
    "    \n",
    "    svm_spaces = get_svm_search_spaces()\n",
    "    svm_results = run_hyperparameter_search(\n",
    "        model_name=\"SVM\",\n",
    "        pipeline=svm_pipeline,\n",
    "        search_spaces=svm_spaces,\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_test=X_test,\n",
    "        y_test=y_test,\n",
    "        cv=cv,\n",
    "    )\n",
    "    all_results.extend(svm_results)\n",
    "    \n",
    "    # ============================================================================\n",
    "    # MLP OPTIMIZATION\n",
    "    # ============================================================================\n",
    "    print(f\"\\n{'#'*80}\")\n",
    "    print(\"# PART 2: MULTI-LAYER PERCEPTRON (MLP) OPTIMIZATION\")\n",
    "    print(f\"{'#'*80}\")\n",
    "    \n",
    "    mlp_pipeline = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", MLPClassifier(random_state=RANDOM_STATE))\n",
    "    ])\n",
    "    \n",
    "    mlp_spaces = get_mlp_search_spaces()\n",
    "    mlp_results = run_hyperparameter_search(\n",
    "        model_name=\"MLP\",\n",
    "        pipeline=mlp_pipeline,\n",
    "        search_spaces=mlp_spaces,\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_test=X_test,\n",
    "        y_test=y_test,\n",
    "        cv=cv,\n",
    "    )\n",
    "    all_results.extend(mlp_results)\n",
    "    \n",
    "    # ============================================================================\n",
    "    # RESULTS ANALYSIS AND VISUALIZATION\n",
    "    # ============================================================================\n",
    "    print(f\"\\n{'#'*80}\")\n",
    "    print(\"# RESULTS ANALYSIS\")\n",
    "    print(f\"{'#'*80}\")\n",
    "    \n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    # Reorder columns for better readability\n",
    "    column_order = [\n",
    "        \"model\", \"strategy\", \"time_s\", \"best_params\",\n",
    "        \"cv_f1_mean\", \"cv_f1_std\",\n",
    "        \"test_f1\", \"test_accuracy\", \"test_precision\", \"test_recall\",\n",
    "        \"test_roc_auc\", \"test_kappa\"\n",
    "    ]\n",
    "    column_order = [col for col in column_order if col in results_df.columns]\n",
    "    other_columns = [col for col in results_df.columns if col not in column_order]\n",
    "    results_df = results_df[column_order + other_columns]\n",
    "    \n",
    "    # Display comprehensive summary\n",
    "    display_results_summary(results_df)\n",
    "    \n",
    "    # Display detailed table\n",
    "    display_detailed_table(results_df)\n",
    "    \n",
    "    # Save results\n",
    "    save_detailed_results(results_df)\n",
    "    \n",
    "    print(\"\\nâœ… Hyperparameter optimization study completed successfully!\")\n",
    "    print(f\"   Total optimization time: {results_df['time_s'].sum():.2f}s\")\n",
    "    print(f\"   Number of configurations tested: {len(results_df)}\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
